# ğŸ“œ MythosQuest - AI Dungeon Master

**A dynamic AI-powered historical roleplaying game.**  
Built with **Flask, Ollama, and Mistral/Gemma**, MythosQuest allows you to immerse yourself in historical storytelling with an AI Dungeon Master.

---

## ğŸ› ï¸ Features
- ğŸŒ **Historical RPG Experience** â€“ Set in real historical periods.
- ğŸ­ **AI Dungeon Master** â€“ Responds dynamically to player choices.
- âš¡ **Memory System** â€“ Keeps track of past decisions for a consistent narrative.
- ğŸ’¬ **Interactive Web Interface** â€“ Play directly in your browser.
- ğŸ”„ **Dockerized Deployment** â€“ Easily run on any server.
- ğŸš€ **Streamed AI Responses** â€“ Faster and more natural gameplay.

---

## ğŸ–¥ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/YOUR_GITHUB_USERNAME/MythosQuest.git
cd MythosQuest
```

### 2ï¸âƒ£ Install Dependencies
#### (Local Setup - Without Docker)
```sh
pip install -r requirements.txt
```
#### (Docker Setup - Recommended)
```sh
docker-compose up --build -d
```

### âš™ï¸ Configuration
#### Environment Variables
MythosQuest runs with default settings, but you can modify the following variables:

| Variable         | Default                     | Description                         |
|-----------------|---------------------------|-------------------------------------|
| FLASK_APP       | ai_dm.py                   | Entry point for the Flask app      |
| OLLAMA_HOST     | http://ollama_server:11434 | Ollama model server address        |
| PYTHONUNBUFFERED | 1                          | Ensures real-time logs             |

---

## ğŸ•¹ï¸ Usage

### 1ï¸âƒ£ Running Locally
```sh
python ai_dm.py
```
Then, open your browser and go to:  
ğŸ“Œ [http://localhost:5000](http://localhost:5000)

### 2ï¸âƒ£ Running in Docker
```sh
docker-compose up --build -d
```
Check logs if needed:
```sh
docker logs -f mythosquest_ai
```

### 3ï¸âƒ£ Testing the API
You can test the API with cURL:
```sh
curl -X POST http://localhost:5000/generate -H "Content-Type: application/json" -d '{"prompt": "Describe a medieval market scene."}'
```

---

## ğŸ”§ Deployment (Oracle Cloud)

### 1ï¸âƒ£ Connect to your Oracle Cloud VM
```sh
ssh ubuntu@YOUR_ORACLE_CLOUD_IP
```

### 2ï¸âƒ£ Install Docker & Git (if not installed)
```sh
sudo apt update && sudo apt install -y docker docker-compose git
```

### 3ï¸âƒ£ Clone & Start the Server
```sh
git clone https://github.com/YOUR_GITHUB_USERNAME/MythosQuest.git
cd MythosQuest
docker-compose up --build -d
```

### 4ï¸âƒ£ Verify Running Containers
```sh
docker ps
```

### 5ï¸âƒ£ Test the API
```sh
curl -X POST http://YOUR_ORACLE_CLOUD_IP:5000/generate -H "Content-Type: application/json" -d '{"prompt": "Describe a medieval market scene."}'
```

---

## ğŸ› ï¸ Troubleshooting

| Issue                     | Solution                                                         |
|---------------------------|-----------------------------------------------------------------|
| Port 5000 not reachable   | Open firewall rules for port 5000 (`sudo ufw allow 5000/tcp`)  |
| Slow AI responses         | Consider upgrading hardware or using an API model instead      |
| Docker errors             | Run `docker-compose down && docker-compose up --build -d`      |
| Model not found           | Ensure Ollama has pulled mistral or gemma (`docker exec -it ollama_server ollama list`) |

---

## ğŸ“œ Roadmap

### âœ… Current Features
- Basic AI Dungeon Master roleplaying
- Persistent memory system
- Web interface & API support
- Oracle Cloud deployment

### ğŸš€ Future Plans
- Fine-tune AI for better roleplay
- Improve UI/UX for smoother gameplay
- Add multiplayer support

---

## ğŸ¤ Contributing
Feel free to fork this repo and submit pull requests!

1. Fork the repository  
2. Create a new branch (`git checkout -b feature-new`)  
3. Commit your changes (`git commit -m "Added new feature"`)  
4. Push your branch (`git push origin feature-new`)  
5. Create a pull request  

---

## ğŸ“œ License
**MIT License** â€“ Free to use, modify, and share!  
Check [LICENSE.md](LICENSE.md) for details.

---

## âœ¨ Credits
- **Flask** for the web interface
- **Ollama** for LLM serving
- **Mistral/Gemma** as AI models